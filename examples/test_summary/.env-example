# Test Retriever Example - Environment Configuration
# Copy this file to .env and configure your values

# =============================================================================
# LLM Configuration
# =============================================================================

# Model name for the OpenAI-compatible API
MODEL_NAME=gpt-5.2

# API endpoint URL (e.g., OpenAI, Azure, local LLM server)
MODEL_URL=https://api.openai.com/v1

# API key for the model provider
API_KEY=<your-api-key-here>

# =============================================================================
# browser_use Worker (Required if using BrowserUseWorkerFactory)
# =============================================================================
#
# browser_use expects OpenAI-compatible auth under OPENAI_API_KEY by default.
# Our worker accepts either OPENAI_API_KEY or API_KEY.
OPENAI_API_KEY=<your-openai-api-key-here>
#
# Tavily API key for multi-query link discovery
TAVILY-PYTHON-RESEARCH-API-KEY=<your-tavily-api-key-here>

# SerpApi fallback (optional). If Tavily is blocked on your network because your company has a communist cyber team, set this instead.
# Requires: `poetry add google-search-results`
SERPAPI_API_KEY=<your-serpapi-api-key-here>

ANONYMIZED_TELEMETRY=false



# =============================================================================
# Langfuse Observability (Optional)
# =============================================================================
# These credentials should match your Langfuse instance.
# Default values work with the included docker-compose.yml setup.

# Set to "false" to disable Langfuse tracing entirely
LANGFUSE_ENABLED=true

# Langfuse credentials (must match values in root .env used by docker-compose)
LANGFUSE_PUBLIC_KEY=<must-match-LANGFUSE_INIT_PROJECT_PUBLIC_KEY>
LANGFUSE_SECRET_KEY=<must-match-LANGFUSE_INIT_PROJECT_SECRET_KEY>
LANGFUSE_HOST=http://localhost:3000
